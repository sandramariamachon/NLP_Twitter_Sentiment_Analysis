{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweepy_Twitter_Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqD9uUVDMZqsfvQhTxxD4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandramariamachon/NLP_Twitter_Sentiment_Analysis/blob/main/Tweepy_Twitter_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F98DB7tZLuur"
      },
      "source": [
        "import tweepy # for tweet mining\n",
        "import csv # to read and write csv files\n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uSDuYXeMc3i"
      },
      "source": [
        "## **Authorisation Codes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTq81RCqMVAa"
      },
      "source": [
        "# Consumer_key and access_key generated from Twitter's developer account\n",
        "CONSUMER_KEY = 'XXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
        "CONSUMER_SECRET = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
        "ACCESS_KEY = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
        "ACCESS_SECRET = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VUREsNpMVDa"
      },
      "source": [
        "# Authorisation code\n",
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) # Pass in Consumer key and secret for authentication by API\n",
        "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET) # Pass in Access key and secret for authentication by API\n",
        "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True) # Sleeps when API limit is reached"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeBxZQEBMo4P"
      },
      "source": [
        "## **Scraping Tweets from API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6mO5SRWMVIr"
      },
      "source": [
        "def get_tweets_in_data_range(data, phrase, max_tweets, end_date, start_date = None, start_via_tweet_id = None):\n",
        "  \"\"\"Scrapes Tweets based on given phrase, beteen dates. Alternatively this can work via a range of start_tweet_id and end date\"\"\"\n",
        "  search_query = phrase + \" -filter:links AND -filter:retweets AND -filter:replies\" #Exclude links, retweets, replies\n",
        "  for i in tweepy.Cursor(api.search, q = search_query, since = start_date, until = end_date, since_id = start_via_tweet_id, lang = \"en\", tweet_mode = \"extended\").items(max_tweets):\n",
        "    data.append([i.full_text, i.id, i.created_at, i.coordinates, i.retweet_count, i.favorite_count]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIX0WIOCMVLa"
      },
      "source": [
        "scraped_data = []\n",
        "scraped_data.append([\"text\", \"id\", \"time\", \"location\", \"retweet_count\", \"fav_count\"])\n",
        "PHRASE = \"\\\"Covid-19\\\"\"\n",
        "MAX_TWEETS = 1000 #Maximum number of tweets to scrape\n",
        "START_DATE = '2021-03-25' #only last 7 days supported\n",
        "END_DATE = '2021-03-26' #only last 7 days supported\n",
        "get_tweets_in_data_range(scraped_data, PHRASE, MAX_TWEETS, END_DATE, START_DATE) #call to get tweets between date ranges \n",
        "#get_tweets_in_data_range(scraped_data, PHRASE, MAX_TWEETS, END_DATE, None, 1375235706382123011) #call to get tweets from a tweet ID to end date (note that the Start_date is set to \"None\" and an a start_via_tweet_id argument is given)\n",
        "#get_tweets_in_data_range(scraped_data, PHRASE, MAX_TWEETS, END_DATE, None, scraped_data[1][1]) #use scraped_data[1][1] after calling \"get_tweets_in_data_range\" once to access the latest id from the last call (to update with latest data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "essTrkl_TiLa"
      },
      "source": [
        "## **Save to CSV via Pandas data frame**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lnvHBG1QUZL"
      },
      "source": [
        "tweets = pd.DataFrame(scraped_data[1:],columns=scraped_data[0])\n",
        "tweets_csv = tweets.to_csv('scraped_data.csv', index=True)  #saves a csv file with the data scraped\n",
        "#print(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}